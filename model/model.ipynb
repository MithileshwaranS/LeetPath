{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Leetcode Problem Recommendation System**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Pre-Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>title</th>\n",
       "      <th>titleSlug</th>\n",
       "      <th>topics</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>questionId</th>\n",
       "      <th>questionFrontendId</th>\n",
       "      <th>question</th>\n",
       "      <th>link</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>likability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54.199137</td>\n",
       "      <td>Two Sum</td>\n",
       "      <td>two-sum</td>\n",
       "      <td>[array, hash-table]</td>\n",
       "      <td>easy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;Given an array of integers &lt;code&gt;nums&lt;/code...</td>\n",
       "      <td>https://leetcode.com/problems/two-sum</td>\n",
       "      <td>58795</td>\n",
       "      <td>2097</td>\n",
       "      <td>96.556198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.566495</td>\n",
       "      <td>Add Two Numbers</td>\n",
       "      <td>add-two-numbers</td>\n",
       "      <td>[linked-list, math, recursion]</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;p&gt;You are given two &lt;strong&gt;non-empty&lt;/strong...</td>\n",
       "      <td>https://leetcode.com/problems/add-two-numbers</td>\n",
       "      <td>32082</td>\n",
       "      <td>6445</td>\n",
       "      <td>83.271472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.730692</td>\n",
       "      <td>Longest Substring Without Repeating Characters</td>\n",
       "      <td>longest-substring-without-repeating-characters</td>\n",
       "      <td>[hash-table, string, sliding-window]</td>\n",
       "      <td>medium</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;p&gt;Given a string &lt;code&gt;s&lt;/code&gt;, find the len...</td>\n",
       "      <td>https://leetcode.com/problems/longest-substrin...</td>\n",
       "      <td>40582</td>\n",
       "      <td>1956</td>\n",
       "      <td>95.401758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.961454</td>\n",
       "      <td>Median of Two Sorted Arrays</td>\n",
       "      <td>median-of-two-sorted-arrays</td>\n",
       "      <td>[array, binary-search, divide-and-conquer]</td>\n",
       "      <td>hard</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;p&gt;Given two sorted arrays &lt;code&gt;nums1&lt;/code&gt; ...</td>\n",
       "      <td>https://leetcode.com/problems/median-of-two-so...</td>\n",
       "      <td>28998</td>\n",
       "      <td>3261</td>\n",
       "      <td>89.891193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.741408</td>\n",
       "      <td>Longest Palindromic Substring</td>\n",
       "      <td>longest-palindromic-substring</td>\n",
       "      <td>[two-pointers, string, dynamic-programming]</td>\n",
       "      <td>medium</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;p&gt;Given a string &lt;code&gt;s&lt;/code&gt;, return &lt;em&gt;t...</td>\n",
       "      <td>https://leetcode.com/problems/longest-palindro...</td>\n",
       "      <td>29884</td>\n",
       "      <td>1837</td>\n",
       "      <td>94.208884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy                                           title  \\\n",
       "0  54.199137                                         Two Sum   \n",
       "1  44.566495                                 Add Two Numbers   \n",
       "2  35.730692  Longest Substring Without Repeating Characters   \n",
       "3  41.961454                     Median of Two Sorted Arrays   \n",
       "4  34.741408                   Longest Palindromic Substring   \n",
       "\n",
       "                                        titleSlug  \\\n",
       "0                                         two-sum   \n",
       "1                                 add-two-numbers   \n",
       "2  longest-substring-without-repeating-characters   \n",
       "3                     median-of-two-sorted-arrays   \n",
       "4                   longest-palindromic-substring   \n",
       "\n",
       "                                        topics difficulty questionId  \\\n",
       "0                          [array, hash-table]       easy          1   \n",
       "1               [linked-list, math, recursion]     medium          2   \n",
       "2         [hash-table, string, sliding-window]     medium          3   \n",
       "3   [array, binary-search, divide-and-conquer]       hard          4   \n",
       "4  [two-pointers, string, dynamic-programming]     medium          5   \n",
       "\n",
       "  questionFrontendId                                           question  \\\n",
       "0                  1  <p>Given an array of integers <code>nums</code...   \n",
       "1                  2  <p>You are given two <strong>non-empty</strong...   \n",
       "2                  3  <p>Given a string <code>s</code>, find the len...   \n",
       "3                  4  <p>Given two sorted arrays <code>nums1</code> ...   \n",
       "4                  5  <p>Given a string <code>s</code>, return <em>t...   \n",
       "\n",
       "                                                link  likes  dislikes  \\\n",
       "0              https://leetcode.com/problems/two-sum  58795      2097   \n",
       "1      https://leetcode.com/problems/add-two-numbers  32082      6445   \n",
       "2  https://leetcode.com/problems/longest-substrin...  40582      1956   \n",
       "3  https://leetcode.com/problems/median-of-two-so...  28998      3261   \n",
       "4  https://leetcode.com/problems/longest-palindro...  29884      1837   \n",
       "\n",
       "   likability  \n",
       "0   96.556198  \n",
       "1   83.271472  \n",
       "2   95.401758  \n",
       "3   89.891193  \n",
       "4   94.208884  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = json.loads(open(\"data.json\", \"r\").read())\n",
    "new_data = defaultdict(list)\n",
    "for key in data.keys():\n",
    "    for attribute in data[key].keys():\n",
    "        new_data[attribute].append(data[key][attribute])\n",
    "\n",
    "with open(\"updated_data.json\", 'w+') as f:\n",
    "    f.write(json.dumps(new_data))\n",
    "\n",
    "df = pd.DataFrame(new_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>title</th>\n",
       "      <th>titleSlug</th>\n",
       "      <th>topics</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>questionId</th>\n",
       "      <th>questionFrontendId</th>\n",
       "      <th>question</th>\n",
       "      <th>link</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>likability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54.199137</td>\n",
       "      <td>Two Sum</td>\n",
       "      <td>two-sum</td>\n",
       "      <td>[array, hash-table]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;Given an array of integers &lt;code&gt;nums&lt;/code...</td>\n",
       "      <td>https://leetcode.com/problems/two-sum</td>\n",
       "      <td>58795</td>\n",
       "      <td>2097</td>\n",
       "      <td>96.556198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.566495</td>\n",
       "      <td>Add Two Numbers</td>\n",
       "      <td>add-two-numbers</td>\n",
       "      <td>[linked-list, math, recursion]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;p&gt;You are given two &lt;strong&gt;non-empty&lt;/strong...</td>\n",
       "      <td>https://leetcode.com/problems/add-two-numbers</td>\n",
       "      <td>32082</td>\n",
       "      <td>6445</td>\n",
       "      <td>83.271472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.730692</td>\n",
       "      <td>Longest Substring Without Repeating Characters</td>\n",
       "      <td>longest-substring-without-repeating-characters</td>\n",
       "      <td>[hash-table, string, sliding-window]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;p&gt;Given a string &lt;code&gt;s&lt;/code&gt;, find the len...</td>\n",
       "      <td>https://leetcode.com/problems/longest-substrin...</td>\n",
       "      <td>40582</td>\n",
       "      <td>1956</td>\n",
       "      <td>95.401758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.961454</td>\n",
       "      <td>Median of Two Sorted Arrays</td>\n",
       "      <td>median-of-two-sorted-arrays</td>\n",
       "      <td>[array, binary-search, divide-and-conquer]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;p&gt;Given two sorted arrays &lt;code&gt;nums1&lt;/code&gt; ...</td>\n",
       "      <td>https://leetcode.com/problems/median-of-two-so...</td>\n",
       "      <td>28998</td>\n",
       "      <td>3261</td>\n",
       "      <td>89.891193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.741408</td>\n",
       "      <td>Longest Palindromic Substring</td>\n",
       "      <td>longest-palindromic-substring</td>\n",
       "      <td>[two-pointers, string, dynamic-programming]</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;p&gt;Given a string &lt;code&gt;s&lt;/code&gt;, return &lt;em&gt;t...</td>\n",
       "      <td>https://leetcode.com/problems/longest-palindro...</td>\n",
       "      <td>29884</td>\n",
       "      <td>1837</td>\n",
       "      <td>94.208884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy                                           title  \\\n",
       "0  54.199137                                         Two Sum   \n",
       "1  44.566495                                 Add Two Numbers   \n",
       "2  35.730692  Longest Substring Without Repeating Characters   \n",
       "3  41.961454                     Median of Two Sorted Arrays   \n",
       "4  34.741408                   Longest Palindromic Substring   \n",
       "\n",
       "                                        titleSlug  \\\n",
       "0                                         two-sum   \n",
       "1                                 add-two-numbers   \n",
       "2  longest-substring-without-repeating-characters   \n",
       "3                     median-of-two-sorted-arrays   \n",
       "4                   longest-palindromic-substring   \n",
       "\n",
       "                                        topics  difficulty questionId  \\\n",
       "0                          [array, hash-table]           1          1   \n",
       "1               [linked-list, math, recursion]           2          2   \n",
       "2         [hash-table, string, sliding-window]           2          3   \n",
       "3   [array, binary-search, divide-and-conquer]           3          4   \n",
       "4  [two-pointers, string, dynamic-programming]           2          5   \n",
       "\n",
       "  questionFrontendId                                           question  \\\n",
       "0                  1  <p>Given an array of integers <code>nums</code...   \n",
       "1                  2  <p>You are given two <strong>non-empty</strong...   \n",
       "2                  3  <p>Given a string <code>s</code>, find the len...   \n",
       "3                  4  <p>Given two sorted arrays <code>nums1</code> ...   \n",
       "4                  5  <p>Given a string <code>s</code>, return <em>t...   \n",
       "\n",
       "                                                link  likes  dislikes  \\\n",
       "0              https://leetcode.com/problems/two-sum  58795      2097   \n",
       "1      https://leetcode.com/problems/add-two-numbers  32082      6445   \n",
       "2  https://leetcode.com/problems/longest-substrin...  40582      1956   \n",
       "3  https://leetcode.com/problems/median-of-two-so...  28998      3261   \n",
       "4  https://leetcode.com/problems/longest-palindro...  29884      1837   \n",
       "\n",
       "   likability  \n",
       "0   96.556198  \n",
       "1   83.271472  \n",
       "2   95.401758  \n",
       "3   89.891193  \n",
       "4   94.208884  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difficulty_map = {\"easy\" : 1, \"medium\" : 2, \"hard\" : 3}\n",
    "\n",
    "df[\"difficulty\"] = df[\"difficulty\"].map(difficulty_map)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy                0\n",
       "title                   0\n",
       "titleSlug               0\n",
       "topics                  0\n",
       "difficulty              0\n",
       "questionId              0\n",
       "questionFrontendId      0\n",
       "question              685\n",
       "link                    0\n",
       "likes                   0\n",
       "dislikes                0\n",
       "likability              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy              2668\n",
       "title                 2668\n",
       "titleSlug             2668\n",
       "topics                2668\n",
       "difficulty            2668\n",
       "questionId            2668\n",
       "questionFrontendId    2668\n",
       "question              2668\n",
       "link                  2668\n",
       "likes                 2668\n",
       "dislikes              2668\n",
       "likability            2668\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index to avoid KeyErrors\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.to_json(\"updated_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Questions: [('find-first-and-last-position-of-element-in-sorted-array', 0.8010920062005068), ('4sum', 0.7975759205069344), ('search-insert-position', 0.795626880116056), ('binary-search', 0.7523763161182005), ('3sum-closest', 0.7429428175506935)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import defaultdict\n",
    "\n",
    "# User solved questions\n",
    "solved_slugs = ['two-sum']\n",
    "\n",
    "# 1. Sentence embeddings for questions\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "df['embedding'] = df['question'].apply(lambda q: model.encode(q, show_progress_bar=False))\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "df[['difficulty', 'likability', 'accuracy']] = scaler.fit_transform(df[['difficulty', 'likability', 'accuracy']])\n",
    "\n",
    "# 2. Build the MRF graph\n",
    "def build_mrf(df):\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        node = row['titleSlug']\n",
    "        G.add_node(node, potential=1.0, embedding=row['embedding'])\n",
    "    \n",
    "    for i, row_i in df.iterrows():\n",
    "        for j, row_j in df.iterrows():\n",
    "            if i >= j:\n",
    "                continue\n",
    "            \n",
    "            # Edge weight: combination of cosine similarity and topic overlap\n",
    "            sim_score = cosine_similarity([row_i['embedding']], [row_j['embedding']])[0][0]\n",
    "            topic_overlap = len(set(row_i['topics']) & set(row_j['topics'])) / len(set(row_i['topics']) | set(row_j['topics']))\n",
    "            edge_weight = 0.7 * sim_score + 0.3 * topic_overlap\n",
    "            \n",
    "            G.add_edge(row_i['titleSlug'], row_j['titleSlug'], weight=edge_weight)\n",
    "    \n",
    "    return G\n",
    "\n",
    "graph = build_mrf(df)\n",
    "\n",
    "# 3. Belief Propagation with Damping\n",
    "def belief_propagation(graph, solved_slugs, max_iters=10, damping=0.5):\n",
    "    beliefs = {node: graph.nodes[node]['potential'] for node in graph.nodes}\n",
    "    previous_beliefs = beliefs.copy()\n",
    "    \n",
    "    for _ in range(max_iters):\n",
    "        for node in graph.nodes:\n",
    "            if node in solved_slugs:\n",
    "                continue\n",
    "            \n",
    "            message = 1.0\n",
    "            for neighbor in graph.neighbors(node):\n",
    "                edge_weight = graph[node][neighbor]['weight']\n",
    "                message *= edge_weight * previous_beliefs[neighbor]\n",
    "            \n",
    "            new_belief = graph.nodes[node]['potential'] * message\n",
    "            beliefs[node] = damping * new_belief + (1 - damping) * previous_beliefs[node]\n",
    "        \n",
    "        previous_beliefs = beliefs.copy()\n",
    "    \n",
    "    # Normalize beliefs\n",
    "    total_belief = sum(beliefs.values())\n",
    "    for node in beliefs:\n",
    "        beliefs[node] /= total_belief\n",
    "    \n",
    "    return beliefs\n",
    "\n",
    "beliefs = belief_propagation(graph, solved_slugs)\n",
    "\n",
    "# 4. Diversify recommendations using MMR\n",
    "def get_recommendations(beliefs, graph, solved_slugs, top_k=5, lambda_div=0.7):\n",
    "    ranked_nodes = sorted(beliefs.items(), key=lambda x: x[1], reverse=True)\n",
    "    recommendations = []\n",
    "    \n",
    "    while len(ranked_nodes) > 0 and len(recommendations) < top_k:\n",
    "        candidate = ranked_nodes.pop(0)\n",
    "        if candidate[0] in solved_slugs:\n",
    "            continue\n",
    "        \n",
    "        # Calculate MMR\n",
    "        mmr_score = lambda_div * candidate[1] - (1 - lambda_div) * max(\n",
    "            [graph[candidate[0]][rec]['weight'] for rec in recommendations] or [0]\n",
    "        )\n",
    "        \n",
    "        recommendations.append((candidate[0], mmr_score))\n",
    "    \n",
    "    return [rec[0] for rec in sorted(recommendations, key=lambda x: x[1], reverse=True)]\n",
    "\n",
    "recommendations = get_recommendations(beliefs, graph, solved_slugs, top_k=5)\n",
    "\n",
    "# 5. Print recommendations\n",
    "print(\"Recommended Questions:\")\n",
    "for rec in recommendations:\n",
    "    print(df[df['titleSlug'] == rec]['titleSlug'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import networkx as nx\n",
    "\n",
    "DF = \n",
    "# Load DataFrame\n",
    "def load_data(file_path=\"updated_data.json\"):\n",
    "    df = pd.read_json(file_path)\n",
    "    df = preprocess_data(df)\n",
    "    return df\n",
    "\n",
    "# Function to preprocess data\n",
    "def preprocess_data(df):\n",
    "    # Normalize 'likability' and 'accuracy'\n",
    "    scaler = MinMaxScaler()\n",
    "    df[['likability', 'accuracy']] = scaler.fit_transform(df[['likability', 'accuracy']])\n",
    "    return df\n",
    "\n",
    "# Function to calculate the joint probability of accuracy and difficulty\n",
    "def calculate_potential_matrix(df):\n",
    "    joint_prob = pd.crosstab(df['accuracy'], df['difficulty'], normalize='all')\n",
    "    \n",
    "    # We will use the joint probability distribution to form the potential matrix\n",
    "    potential_matrix = np.zeros((2, 3))  # 2 values for accuracy (0, 1) and 3 values for difficulty (1, 2, 3)\n",
    "    \n",
    "    # Fill the potential matrix based on the joint distribution\n",
    "    for acc in range(2):  # Accuracy can be 0 or 1\n",
    "        for diff in range(1, 4):  # Difficulty can be 1, 2, or 3\n",
    "            if diff in joint_prob.columns:\n",
    "                potential_matrix[acc, diff-1] = joint_prob.loc[acc, diff] if acc in joint_prob.index else 0\n",
    "    \n",
    "    return potential_matrix\n",
    "\n",
    "# Markov Random Field (MRF) Implementation\n",
    "class MarkovRandomField:\n",
    "    def __init__(self):\n",
    "        self.edges = {}\n",
    "        self.nodes = {}\n",
    "        self.potentials = {}\n",
    "    \n",
    "    def add_edge(self, node1, node2, potential):\n",
    "        if node1 not in self.nodes:\n",
    "            self.nodes[node1] = {}\n",
    "        if node2 not in self.nodes:\n",
    "            self.nodes[node2] = {}\n",
    "        \n",
    "        # Store the potential in the 'potentials' dictionary\n",
    "        self.potentials[(node1, node2)] = potential\n",
    "    \n",
    "    def compute_potential(self, node1, node2, val1, val2):\n",
    "        # Access the potential matrix for the edge (node1, node2)\n",
    "        return self.potentials[(node1, node2)][val1, val2]\n",
    "\n",
    "# Belief Propagation Implementation\n",
    "def belief_propagation(mrf, max_iter=10):\n",
    "    messages = {}\n",
    "    \n",
    "    # Initialize messages to ones\n",
    "    for (node1, node2) in mrf.edges:\n",
    "        messages[(node1, node2)] = np.ones(2)  # Uniform initialization for binary values (0, 1)\n",
    "    \n",
    "    # Perform message updates\n",
    "    for _ in range(max_iter):\n",
    "        for (node1, node2) in mrf.edges:\n",
    "            # We assume that nodes are binary (0, 1) for 'accuracy' and categorical for 'difficulty'\n",
    "            incoming_messages = np.prod([messages[(nbr, node1)] for nbr in mrf.nodes[node1] if nbr != node2], axis=0)\n",
    "            \n",
    "            # We need to calculate messages correctly: values for each node (0 or 1 for accuracy)\n",
    "            for val1 in range(2):  # For accuracy, which can take values 0 or 1\n",
    "                for val2 in range(3):  # For difficulty, which can take values 1, 2, or 3\n",
    "                    # Update the message with the correct potential value\n",
    "                    messages[(node1, node2)] = mrf.compute_potential(node1, node2, val1, val2)\n",
    "    \n",
    "    return messages\n",
    "\n",
    "# Custom Topic Modeling (similar to LDA)\n",
    "def custom_topic_model(corpus, n_topics=2, alpha=0.1, beta=0.01):\n",
    "    vocab = {word: idx for idx, word in enumerate(set(' '.join(corpus).split()))}\n",
    "    word_topic_matrix = np.zeros((len(vocab), n_topics))\n",
    "    doc_topic_matrix = np.zeros((len(corpus), n_topics))\n",
    "    \n",
    "    doc_word_topic = []\n",
    "    for i, doc in enumerate(corpus):\n",
    "        topics = []\n",
    "        for word in doc.split():\n",
    "            topic = np.random.randint(0, n_topics)\n",
    "            topics.append(topic)\n",
    "            word_topic_matrix[vocab[word], topic] += 1\n",
    "            doc_topic_matrix[i, topic] += 1\n",
    "        doc_word_topic.append(topics)\n",
    "    \n",
    "    for _ in range(50):\n",
    "        for d, doc in enumerate(corpus):\n",
    "            for i, word in enumerate(doc.split()):\n",
    "                topic = doc_word_topic[d][i]\n",
    "                word_topic_matrix[vocab[word], topic] -= 1\n",
    "                doc_topic_matrix[d, topic] -= 1\n",
    "                \n",
    "                topic_dist = (word_topic_matrix[vocab[word], :] + beta) * (doc_topic_matrix[d, :] + alpha)\n",
    "                new_topic = np.argmax(topic_dist / topic_dist.sum())\n",
    "                \n",
    "                doc_word_topic[d][i] = new_topic\n",
    "                word_topic_matrix[vocab[word], new_topic] += 1\n",
    "                doc_topic_matrix[d, new_topic] += 1\n",
    "    \n",
    "    return doc_topic_matrix / doc_topic_matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Calculate topic overlap between two documents\n",
    "def topic_overlap(doc1_topics, doc2_topics):\n",
    "    return np.sum(np.minimum(doc1_topics, doc2_topics))\n",
    "\n",
    "# Build Graph with Adjusted Weights for Topic Overlap and Content Similarity\n",
    "def build_graph(df, similarity_matrix, solved_questions, topic_matrix):\n",
    "    G = nx.Graph()\n",
    "    for idx, row in df.iterrows():\n",
    "        G.add_node(row['titleSlug'], difficulty=row['difficulty'], likability=row['likability'], accuracy=row['accuracy'])\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        for j in range(i + 1, len(df)):\n",
    "            prob = np.random.random()  # Mock for Bayesian Probability\n",
    "            content_similarity = similarity_matrix[i, j]\n",
    "            topic_overlap_score = topic_overlap(topic_matrix[i], topic_matrix[j])\n",
    "            \n",
    "            # Adjust edge weight based on both content similarity and topic overlap\n",
    "            combined_weight = (content_similarity + topic_overlap_score) / 2\n",
    "            G.add_edge(df.loc[i, 'titleSlug'], df.loc[j, 'titleSlug'], weight=combined_weight)\n",
    "    \n",
    "    return G\n",
    "\n",
    "def recommend_questions(solved_questions, top_n=3, df=None):\n",
    "    # If DataFrame is not passed, load it\n",
    "    if df is None:\n",
    "        df = load_data()\n",
    "\n",
    "    question_vectors = TfidfVectorizer().fit_transform(df['question'])\n",
    "    similarity_matrix = cosine_similarity(question_vectors)\n",
    "\n",
    "    # Topic modeling (using custom topic model or any other topic model)\n",
    "    topic_matrix = custom_topic_model(df['question'].tolist(), n_topics=3)\n",
    "\n",
    "    # Dynamically calculate the potential matrix from data\n",
    "    potential_matrix = calculate_potential_matrix(df)\n",
    "\n",
    "    mrf = MarkovRandomField()\n",
    "    mrf.add_edge('accuracy', 'difficulty', potential_matrix)\n",
    "\n",
    "    # Perform belief propagation\n",
    "    cpt = belief_propagation(mrf)\n",
    "\n",
    "    # Build the graph with adjusted weights for similarity and topic overlap\n",
    "    G = build_graph(df, similarity_matrix, solved_questions, topic_matrix)\n",
    "\n",
    "    # Get the top N recommended questions\n",
    "    recommendations = {}\n",
    "    for solved in solved_questions:\n",
    "        if solved not in G:\n",
    "            continue\n",
    "        neighbors = sorted(G[solved].items(), key=lambda x: x[1]['weight'], reverse=True)\n",
    "        for neighbor, _ in neighbors:\n",
    "            if neighbor not in solved_questions:\n",
    "                recommendations[neighbor] = G[solved][neighbor]['weight']\n",
    "\n",
    "    return sorted(recommendations.items(), key=lambda x: x[1], reverse=True)[:top_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: [('add-two-numbers-ii', 0.9366081613936407), ('merge-nodes-in-between-zeros', 0.7158952687162674), ('convert-binary-number-in-a-linked-list-to-integer', 0.7112255347854736)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import networkx as nx\n",
    "\n",
    "class QuestionRecommender:\n",
    "    def __init__(self, file_path=\"updated_data.json\"):\n",
    "        self.df = self.load_and_preprocess_data(file_path)\n",
    "        self.similarity_matrix = None\n",
    "        self.topic_matrix = None\n",
    "        self.potential_matrix = None\n",
    "        self.mrf = None\n",
    "        self.G = None\n",
    "\n",
    "        # Pre-calculate matrices and graph once\n",
    "        self.calculate_similarity_matrix()\n",
    "        self.calculate_topic_matrix()\n",
    "        self.calculate_potential_matrix()\n",
    "        self.build_graph()\n",
    "\n",
    "    # Load and preprocess DataFrame only once\n",
    "    def load_and_preprocess_data(self, file_path):\n",
    "        df = pd.read_json(file_path)\n",
    "        df = self.preprocess_data(df)\n",
    "        return df\n",
    "\n",
    "    # Preprocess data (normalizing 'likability' and 'accuracy')\n",
    "    def preprocess_data(self, df):\n",
    "        scaler = MinMaxScaler()\n",
    "        df[['likability', 'accuracy']] = scaler.fit_transform(df[['likability', 'accuracy']])\n",
    "        return df\n",
    "\n",
    "    # Function to calculate the similarity matrix using TF-IDF\n",
    "    def calculate_similarity_matrix(self):\n",
    "        question_vectors = TfidfVectorizer().fit_transform(self.df['question'])\n",
    "        self.similarity_matrix = cosine_similarity(question_vectors)\n",
    "\n",
    "    # Function to calculate the topic matrix (using custom topic model)\n",
    "    def calculate_topic_matrix(self):\n",
    "        self.topic_matrix = self.custom_topic_model(self.df['question'].tolist(), n_topics=3)\n",
    "\n",
    "    # Function to calculate the joint probability of accuracy and difficulty (potential matrix)\n",
    "    def calculate_potential_matrix(self):\n",
    "        joint_prob = pd.crosstab(self.df['accuracy'], self.df['difficulty'], normalize='all')\n",
    "        self.potential_matrix = np.zeros((2, 3))  # 2 values for accuracy (0, 1) and 3 values for difficulty (1, 2, 3)\n",
    "        \n",
    "        for acc in range(2):  # Accuracy can be 0 or 1\n",
    "            for diff in range(1, 4):  # Difficulty can be 1, 2, or 3\n",
    "                if diff in joint_prob.columns:\n",
    "                    self.potential_matrix[acc, diff-1] = joint_prob.loc[acc, diff] if acc in joint_prob.index else 0\n",
    "\n",
    "    # Markov Random Field (MRF) Implementation\n",
    "    class MarkovRandomField:\n",
    "        def __init__(self):\n",
    "            self.edges = {}\n",
    "            self.nodes = {}\n",
    "            self.potentials = {}\n",
    "        \n",
    "        def add_edge(self, node1, node2, potential):\n",
    "            if node1 not in self.nodes:\n",
    "                self.nodes[node1] = {}\n",
    "            if node2 not in self.nodes:\n",
    "                self.nodes[node2] = {}\n",
    "            \n",
    "            self.potentials[(node1, node2)] = potential\n",
    "        \n",
    "        def compute_potential(self, node1, node2, val1, val2):\n",
    "            return self.potentials[(node1, node2)][val1, val2]\n",
    "\n",
    "    # Belief Propagation Implementation\n",
    "    def belief_propagation(self, mrf, max_iter=10):\n",
    "        messages = {}\n",
    "        \n",
    "        # Initialize messages to ones\n",
    "        for (node1, node2) in mrf.edges:\n",
    "            messages[(node1, node2)] = np.ones(2)  # Uniform initialization for binary values (0, 1)\n",
    "        \n",
    "        for _ in range(max_iter):\n",
    "            for (node1, node2) in mrf.edges:\n",
    "                incoming_messages = np.prod([messages[(nbr, node1)] for nbr in mrf.nodes[node1] if nbr != node2], axis=0)\n",
    "                \n",
    "                for val1 in range(2):  # For accuracy, which can take values 0 or 1\n",
    "                    for val2 in range(3):  # For difficulty, which can take values 1, 2, or 3\n",
    "                        messages[(node1, node2)] = mrf.compute_potential(node1, node2, val1, val2)\n",
    "        \n",
    "        return messages\n",
    "\n",
    "    # Custom Topic Modeling (similar to LDA)\n",
    "    def custom_topic_model(self, corpus, n_topics=2, alpha=0.1, beta=0.01):\n",
    "        vocab = {word: idx for idx, word in enumerate(set(' '.join(corpus).split()))}\n",
    "        word_topic_matrix = np.zeros((len(vocab), n_topics))\n",
    "        doc_topic_matrix = np.zeros((len(corpus), n_topics))\n",
    "        \n",
    "        doc_word_topic = []\n",
    "        for i, doc in enumerate(corpus):\n",
    "            topics = []\n",
    "            for word in doc.split():\n",
    "                topic = np.random.randint(0, n_topics)\n",
    "                topics.append(topic)\n",
    "                word_topic_matrix[vocab[word], topic] += 1\n",
    "                doc_topic_matrix[i, topic] += 1\n",
    "            doc_word_topic.append(topics)\n",
    "        \n",
    "        for _ in range(50):\n",
    "            for d, doc in enumerate(corpus):\n",
    "                for i, word in enumerate(doc.split()):\n",
    "                    topic = doc_word_topic[d][i]\n",
    "                    word_topic_matrix[vocab[word], topic] -= 1\n",
    "                    doc_topic_matrix[d, topic] -= 1\n",
    "                    \n",
    "                    topic_dist = (word_topic_matrix[vocab[word], :] + beta) * (doc_topic_matrix[d, :] + alpha)\n",
    "                    new_topic = np.argmax(topic_dist / topic_dist.sum())\n",
    "                    \n",
    "                    doc_word_topic[d][i] = new_topic\n",
    "                    word_topic_matrix[vocab[word], new_topic] += 1\n",
    "                    doc_topic_matrix[d, new_topic] += 1\n",
    "        \n",
    "        return doc_topic_matrix / doc_topic_matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "    # Calculate topic overlap between two documents\n",
    "    def topic_overlap(self, doc1_topics, doc2_topics):\n",
    "        return np.sum(np.minimum(doc1_topics, doc2_topics))\n",
    "\n",
    "    # Build Graph with Adjusted Weights for Topic Overlap and Content Similarity\n",
    "    def build_graph(self):\n",
    "        self.G = nx.Graph()\n",
    "        for idx, row in self.df.iterrows():\n",
    "            self.G.add_node(row['titleSlug'], difficulty=row['difficulty'], likability=row['likability'], accuracy=row['accuracy'])\n",
    "        \n",
    "        for i in range(len(self.df)):\n",
    "            for j in range(i + 1, len(self.df)):\n",
    "                prob = np.random.random()  # Mock for Bayesian Probability\n",
    "                content_similarity = self.similarity_matrix[i, j]\n",
    "                topic_overlap_score = self.topic_overlap(self.topic_matrix[i], self.topic_matrix[j])\n",
    "                \n",
    "                combined_weight = (content_similarity + topic_overlap_score) / 2\n",
    "                self.G.add_edge(self.df.loc[i, 'titleSlug'], self.df.loc[j, 'titleSlug'], weight=combined_weight)\n",
    "\n",
    "    # Function to recommend questions based on solved questions\n",
    "    def recommend_questions(self, solved_questions, top_n=3):\n",
    "        recommendations = {}\n",
    "        for solved in solved_questions:\n",
    "            if solved not in self.G:\n",
    "                continue\n",
    "            neighbors = sorted(self.G[solved].items(), key=lambda x: x[1]['weight'], reverse=True)\n",
    "            for neighbor, _ in neighbors:\n",
    "                if neighbor not in solved_questions:\n",
    "                    recommendations[neighbor] = self.G[solved][neighbor]['weight']\n",
    "\n",
    "        return sorted(recommendations.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "# Example usage:\n",
    "recommender = QuestionRecommender()  # Load and preprocess once\n",
    "solved_questions = [\"two-sum\", \"add-two-numbers\"]\n",
    "top_n = 3\n",
    "recommended = recommender.recommend_questions(solved_questions, top_n)\n",
    "print(\"Recommendations:\", recommended)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: [('find-bottom-left-tree-value', 0.7848700913010869), ('unique-binary-search-trees', 0.750924606009741), ('balanced-binary-tree', 0.7479847047715535), ('find-duplicate-subtrees', 0.7471498169598703), ('merge-bsts-to-create-single-bst', 0.742378234003862), ('validate-binary-search-tree', 0.7362942750998073), ('unique-binary-search-trees-ii', 0.7308563360277761), ('rotate-list', 0.7245097755348765), ('sort-list', 0.723826635932493), ('two-sum-iv-input-is-a-bst', 0.7232214571714125)]\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "solved_questions = [\"integer-to-roman\", \"same-tree\"]\n",
    "top_n = 10\n",
    "recommended = recommender.recommend_questions(solved_questions, top_n)\n",
    "print(\"Recommendations:\", recommended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **User Skill Level & Tine Out**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import networkx as nx\n",
    "\n",
    "class QuestionRecommender:\n",
    "    def __init__(self, file_path=\"updated_data.json\"):\n",
    "        self.df = self.load_and_preprocess_data(file_path)\n",
    "        self.similarity_matrix = None\n",
    "        self.topic_matrix = None\n",
    "        self.potential_matrix = None\n",
    "        self.mrf = None\n",
    "        self.G = None\n",
    "        self.user_skill_levels = {}  # Store skill levels for users\n",
    "        self.user_solved_problems = {}  # Track solved problems by user\n",
    "        self.timeout_problems = {}  # Problems that are 'timed out' for the user\n",
    "\n",
    "        # Pre-calculate matrices and graph once\n",
    "        self.calculate_similarity_matrix()\n",
    "        self.calculate_topic_matrix()\n",
    "        self.calculate_potential_matrix()\n",
    "        self.build_graph()\n",
    "\n",
    "    def load_and_preprocess_data(self, file_path):\n",
    "        df = pd.read_json(file_path)\n",
    "        df = self.preprocess_data(df)\n",
    "        return df\n",
    "\n",
    "    def preprocess_data(self, df):\n",
    "        scaler = MinMaxScaler()\n",
    "        df[['likability', 'accuracy']] = scaler.fit_transform(df[['likability', 'accuracy']])\n",
    "        return df\n",
    "\n",
    "    def calculate_similarity_matrix(self):\n",
    "        question_vectors = TfidfVectorizer().fit_transform(self.df['question'])\n",
    "        self.similarity_matrix = cosine_similarity(question_vectors)\n",
    "\n",
    "    def calculate_topic_matrix(self):\n",
    "        self.topic_matrix = self.custom_topic_model(self.df['question'].tolist(), n_topics=3)\n",
    "\n",
    "    def calculate_potential_matrix(self):\n",
    "        joint_prob = pd.crosstab(self.df['accuracy'], self.df['difficulty'], normalize='all')\n",
    "        self.potential_matrix = np.zeros((2, 3))\n",
    "        \n",
    "        for acc in range(2):\n",
    "            for diff in range(1, 4):\n",
    "                if diff in joint_prob.columns:\n",
    "                    self.potential_matrix[acc, diff-1] = joint_prob.loc[acc, diff] if acc in joint_prob.index else 0\n",
    "\n",
    "    class MarkovRandomField:\n",
    "        def __init__(self):\n",
    "            self.edges = {}\n",
    "            self.nodes = {}\n",
    "            self.potentials = {}\n",
    "        \n",
    "        def add_edge(self, node1, node2, potential):\n",
    "            if node1 not in self.nodes:\n",
    "                self.nodes[node1] = {}\n",
    "            if node2 not in self.nodes:\n",
    "                self.nodes[node2] = {}\n",
    "            \n",
    "            self.potentials[(node1, node2)] = potential\n",
    "        \n",
    "        def compute_potential(self, node1, node2, val1, val2):\n",
    "            return self.potentials[(node1, node2)][val1, val2]\n",
    "\n",
    "    def belief_propagation(self, mrf, max_iter=10):\n",
    "        messages = {}\n",
    "        \n",
    "        for (node1, node2) in mrf.edges:\n",
    "            messages[(node1, node2)] = np.ones(2)  # Uniform initialization for binary values (0, 1)\n",
    "        \n",
    "        for _ in range(max_iter):\n",
    "            for (node1, node2) in mrf.edges:\n",
    "                incoming_messages = np.prod([messages[(nbr, node1)] for nbr in mrf.nodes[node1] if nbr != node2], axis=0)\n",
    "                \n",
    "                for val1 in range(2):\n",
    "                    for val2 in range(3):\n",
    "                        messages[(node1, node2)] = mrf.compute_potential(node1, node2, val1, val2)\n",
    "        \n",
    "        return messages\n",
    "\n",
    "    def custom_topic_model(self, corpus, n_topics=2, alpha=0.1, beta=0.01):\n",
    "        vocab = {word: idx for idx, word in enumerate(set(' '.join(corpus).split()))}\n",
    "        word_topic_matrix = np.zeros((len(vocab), n_topics))\n",
    "        doc_topic_matrix = np.zeros((len(corpus), n_topics))\n",
    "        \n",
    "        doc_word_topic = []\n",
    "        for i, doc in enumerate(corpus):\n",
    "            topics = []\n",
    "            for word in doc.split():\n",
    "                topic = np.random.randint(0, n_topics)\n",
    "                topics.append(topic)\n",
    "                word_topic_matrix[vocab[word], topic] += 1\n",
    "                doc_topic_matrix[i, topic] += 1\n",
    "            doc_word_topic.append(topics)\n",
    "        \n",
    "        for _ in range(50):\n",
    "            for d, doc in enumerate(corpus):\n",
    "                for i, word in enumerate(doc.split()):\n",
    "                    topic = doc_word_topic[d][i]\n",
    "                    word_topic_matrix[vocab[word], topic] -= 1\n",
    "                    doc_topic_matrix[d, topic] -= 1\n",
    "                    \n",
    "                    topic_dist = (word_topic_matrix[vocab[word], :] + beta) * (doc_topic_matrix[d, :] + alpha)\n",
    "                    new_topic = np.argmax(topic_dist / topic_dist.sum())\n",
    "                    \n",
    "                    doc_word_topic[d][i] = new_topic\n",
    "                    word_topic_matrix[vocab[word], new_topic] += 1\n",
    "                    doc_topic_matrix[d, new_topic] += 1\n",
    "        \n",
    "        return doc_topic_matrix / doc_topic_matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "    def topic_overlap(self, doc1_topics, doc2_topics):\n",
    "        return np.sum(np.minimum(doc1_topics, doc2_topics))\n",
    "\n",
    "    def build_graph(self):\n",
    "        self.G = nx.Graph()\n",
    "        for idx, row in self.df.iterrows():\n",
    "            self.G.add_node(row['titleSlug'], difficulty=row['difficulty'], likability=row['likability'], accuracy=row['accuracy'])\n",
    "        \n",
    "        for i in range(len(self.df)):\n",
    "            for j in range(i + 1, len(self.df)):\n",
    "                prob = np.random.random()  \n",
    "                content_similarity = self.similarity_matrix[i, j]\n",
    "                topic_overlap_score = self.topic_overlap(self.topic_matrix[i], self.topic_matrix[j])\n",
    "                \n",
    "                combined_weight = (content_similarity + topic_overlap_score) / 2\n",
    "                self.G.add_edge(self.df.loc[i, 'titleSlug'], self.df.loc[j, 'titleSlug'], weight=combined_weight)\n",
    "\n",
    "    def recommend_questions(self, user_id, solved_questions, top_n=3):\n",
    "        # Initialize user skill level if not already set\n",
    "        if user_id not in self.user_skill_levels:\n",
    "            self.user_skill_levels[user_id] = 50  # Default skill level (1 to 100)\n",
    "        \n",
    "        recommendations = {}\n",
    "        \n",
    "        for solved in solved_questions:\n",
    "            if solved not in self.G:\n",
    "                continue\n",
    "            neighbors = sorted(self.G[solved].items(), key=lambda x: x[1]['weight'], reverse=True)\n",
    "            for neighbor, _ in neighbors:\n",
    "                if neighbor not in solved_questions and neighbor not in self.timeout_problems.get(user_id, []):\n",
    "                    problem_difficulty = self.df[self.df['titleSlug'] == neighbor]['difficulty'].values[0]\n",
    "                    # Map difficulty to skill level (adjust as per requirements)\n",
    "                    mapped_difficulty = self.difficulty_to_skill_level(problem_difficulty)\n",
    "                    \n",
    "                    # Only recommend problems that match user's current skill level\n",
    "                    if mapped_difficulty <= self.user_skill_levels[user_id]:\n",
    "                        recommendations[neighbor] = self.G[solved][neighbor]['weight']\n",
    "\n",
    "        sorted_recommendations = sorted(recommendations.items(), key=lambda x: x[1], reverse=True)\n",
    "        return sorted_recommendations[:top_n]\n",
    "\n",
    "    def difficulty_to_skill_level(self, difficulty):\n",
    "        # Map problem difficulty (1-5) to a skill level (1-100)\n",
    "        skill_mapping = {1: 20, 2: 40, 3: 60, 4: 80, 5: 100}  # Customize as needed\n",
    "        return skill_mapping.get(difficulty, 50)\n",
    "\n",
    "    def update_skill_level(self, user_id, problem, solved):\n",
    "        # Update user skill level after solving or timing out a problem based on difficulty\n",
    "        problem_difficulty = self.df[self.df['titleSlug'] == problem]['difficulty'].values[0]\n",
    "        mapped_difficulty = self.difficulty_to_skill_level(problem_difficulty)\n",
    "        \n",
    "        if solved:\n",
    "            # If the user solved the problem, increase their skill level\n",
    "            self.user_skill_levels[user_id] = min(self.user_skill_levels[user_id] + (mapped_difficulty // 10), 100)\n",
    "        else:\n",
    "            # Mark the problem as 'timed out' and don't recommend until the user reaches the required skill level\n",
    "            if user_id not in self.timeout_problems:\n",
    "                self.timeout_problems[user_id] = []\n",
    "            self.timeout_problems[user_id].append(problem)\n",
    "\n",
    "    def reset_timeout_problems(self, user_id):\n",
    "        # Reset timeout problems for users who reach the highest skill level\n",
    "        if self.user_skill_levels.get(user_id, 0) == 100:\n",
    "            self.timeout_problems[user_id] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('add-two-numbers-ii', np.float64(0.9363931076301998)), ('convert-binary-number-in-a-linked-list-to-integer', np.float64(0.7192900509145057)), ('merge-nodes-in-between-zeros', np.float64(0.7191100249745019)), ('swapping-nodes-in-a-linked-list', np.float64(0.7114226741622482)), ('sort-list', np.float64(0.7110043002136168)), ('reverse-linked-list', np.float64(0.7102194657114697)), ('double-a-number-represented-as-a-linked-list', np.float64(0.7075104463777359)), ('remove-duplicates-from-sorted-list-ii', np.float64(0.7070358581962383)), ('remove-duplicates-from-sorted-list', np.float64(0.7016625457474788)), ('odd-even-linked-list', np.float64(0.7005874766742842))]\n"
     ]
    }
   ],
   "source": [
    "# Usage Example:\n",
    "recommender = QuestionRecommender()\n",
    "\n",
    "# Initialize user and solved questions\n",
    "user_id = '1'\n",
    "solved_questions = [\"two-sum\", \"add-two-numbers\"]\n",
    "# Recommend questions based on the user's current skill level\n",
    "recommendations = recommender.recommend_questions(user_id, solved_questions, 10)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update skill level after solving a problem\n",
    "recommender.update_skill_level(user_id, 'add-two-numbers-ii', solved=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('convert-binary-number-in-a-linked-list-to-integer', np.float64(0.7192900509145057)), ('merge-nodes-in-between-zeros', np.float64(0.7191100249745019)), ('swapping-nodes-in-a-linked-list', np.float64(0.7114226741622482)), ('sort-list', np.float64(0.7110043002136168)), ('reverse-linked-list', np.float64(0.7102194657114697)), ('double-a-number-represented-as-a-linked-list', np.float64(0.7075104463777359)), ('remove-duplicates-from-sorted-list-ii', np.float64(0.7070358581962383)), ('remove-duplicates-from-sorted-list', np.float64(0.7016625457474788)), ('odd-even-linked-list', np.float64(0.7005874766742842)), ('find-n-unique-integers-sum-up-to-zero', np.float64(0.6993016240310461))]\n"
     ]
    }
   ],
   "source": [
    "# # Usage Example:\n",
    "# recommender = QuestionRecommender()\n",
    "\n",
    "# # Initialize user and solved questions\n",
    "# user_id = '1'\n",
    "solved_questions = [\"two-sum\", \"add-two-numbers\"]\n",
    "# Recommend questions based on the user's current skill level\n",
    "recommendations = recommender.recommend_questions(user_id, solved_questions, 10)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "class QuestionRecommender:\n",
    "    def __init__(self, file_path=\"updated_data.json\", skill_file=\"user_skill_levels.json\"):\n",
    "        self.df = self.load_and_preprocess_data(file_path)\n",
    "        self.skill_file = skill_file\n",
    "        self.similarity_matrix = None\n",
    "        self.topic_matrix = None\n",
    "        self.potential_matrix = None\n",
    "        self.mrf = None\n",
    "        self.G = None\n",
    "        self.user_skill_levels = self.load_user_skill_levels()  # Load skill levels from JSON\n",
    "        self.user_solved_problems = {}  # Track solved problems by user\n",
    "        self.timeout_problems = {}  # Problems that are 'timed out' for the user\n",
    "\n",
    "        # Pre-calculate matrices and graph once\n",
    "        self.calculate_similarity_matrix()\n",
    "        self.calculate_topic_matrix()\n",
    "        self.calculate_potential_matrix()\n",
    "        self.build_graph()\n",
    "\n",
    "    def load_and_preprocess_data(self, file_path):\n",
    "        df = pd.read_json(file_path)\n",
    "        df = self.preprocess_data(df)\n",
    "        return df\n",
    "\n",
    "    def preprocess_data(self, df):\n",
    "        scaler = MinMaxScaler()\n",
    "        df[['likability', 'accuracy']] = scaler.fit_transform(df[['likability', 'accuracy']])\n",
    "        return df\n",
    "\n",
    "    def load_user_skill_levels(self):\n",
    "        # Load the user skill levels from a JSON file\n",
    "        try:\n",
    "            with open(self.skill_file, 'r') as f:\n",
    "                return json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            return {}  # Return empty dict if the file doesn't exist\n",
    "\n",
    "    def save_user_skill_levels(self):\n",
    "        # Save the user skill levels to the JSON file\n",
    "        with open(self.skill_file, 'w') as f:\n",
    "            json.dump(self.user_skill_levels, f, indent=4)\n",
    "\n",
    "    def calculate_similarity_matrix(self):\n",
    "        question_vectors = TfidfVectorizer().fit_transform(self.df['question'])\n",
    "        self.similarity_matrix = cosine_similarity(question_vectors)\n",
    "\n",
    "    def calculate_topic_matrix(self):\n",
    "        self.topic_matrix = self.custom_topic_model(self.df['question'].tolist(), n_topics=3)\n",
    "\n",
    "    def calculate_potential_matrix(self):\n",
    "        joint_prob = pd.crosstab(self.df['accuracy'], self.df['difficulty'], normalize='all')\n",
    "        self.potential_matrix = np.zeros((2, 3))\n",
    "\n",
    "        for acc in range(2):\n",
    "            for diff in range(1, 4):\n",
    "                if diff in joint_prob.columns:\n",
    "                    self.potential_matrix[acc, diff - 1] = joint_prob.loc[acc, diff] if acc in joint_prob.index else 0\n",
    "\n",
    "    class MarkovRandomField:\n",
    "        def __init__(self):\n",
    "            self.edges = {}\n",
    "            self.nodes = {}\n",
    "            self.potentials = {}\n",
    "\n",
    "        def add_edge(self, node1, node2, potential):\n",
    "            if node1 not in self.nodes:\n",
    "                self.nodes[node1] = {}\n",
    "            if node2 not in self.nodes:\n",
    "                self.nodes[node2] = {}\n",
    "\n",
    "            self.potentials[(node1, node2)] = potential\n",
    "\n",
    "        def compute_potential(self, node1, node2, val1, val2):\n",
    "            return self.potentials[(node1, node2)][val1, val2]\n",
    "\n",
    "    def belief_propagation(self, mrf, max_iter=10):\n",
    "        messages = {}\n",
    "\n",
    "        # Initialize messages\n",
    "        for (node1, node2) in mrf.edges:\n",
    "            messages[(node1, node2)] = np.ones(2)  # Uniform initialization for binary values (0, 1)\n",
    "\n",
    "        for _ in range(max_iter):\n",
    "            for (node1, node2) in mrf.edges:\n",
    "                incoming_messages = np.prod([messages[(nbr, node1)] for nbr in mrf.nodes[node1] if nbr != node2], axis=0)\n",
    "\n",
    "                for val1 in range(2):\n",
    "                    for val2 in range(3):\n",
    "                        messages[(node1, node2)] = mrf.compute_potential(node1, node2, val1, val2)\n",
    "\n",
    "        return messages\n",
    "\n",
    "    def custom_topic_model(self, corpus, n_topics=2, alpha=0.1, beta=0.01):\n",
    "        vocab = {word: idx for idx, word in enumerate(set(' '.join(corpus).split()))}\n",
    "        word_topic_matrix = np.zeros((len(vocab), n_topics))\n",
    "        doc_topic_matrix = np.zeros((len(corpus), n_topics))\n",
    "\n",
    "        doc_word_topic = []\n",
    "        for i, doc in enumerate(corpus):\n",
    "            topics = []\n",
    "            for word in doc.split():\n",
    "                topic = np.random.randint(0, n_topics)\n",
    "                topics.append(topic)\n",
    "                word_topic_matrix[vocab[word], topic] += 1\n",
    "                doc_topic_matrix[i, topic] += 1\n",
    "            doc_word_topic.append(topics)\n",
    "\n",
    "        for _ in range(50):\n",
    "            for d, doc in enumerate(corpus):\n",
    "                for i, word in enumerate(doc.split()):\n",
    "                    topic = doc_word_topic[d][i]\n",
    "                    word_topic_matrix[vocab[word], topic] -= 1\n",
    "                    doc_topic_matrix[d, topic] -= 1\n",
    "\n",
    "                    topic_dist = (word_topic_matrix[vocab[word], :] + beta) * (doc_topic_matrix[d, :] + alpha)\n",
    "                    new_topic = np.argmax(topic_dist / topic_dist.sum())\n",
    "\n",
    "                    doc_word_topic[d][i] = new_topic\n",
    "                    word_topic_matrix[vocab[word], new_topic] += 1\n",
    "                    doc_topic_matrix[d, new_topic] += 1\n",
    "\n",
    "        return doc_topic_matrix / doc_topic_matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "    def topic_overlap(self, doc1_topics, doc2_topics):\n",
    "        return np.sum(np.minimum(doc1_topics, doc2_topics))\n",
    "\n",
    "    def build_graph(self):\n",
    "        self.G = nx.Graph()\n",
    "        for idx, row in self.df.iterrows():\n",
    "            self.G.add_node(row['titleSlug'], difficulty=row['difficulty'], likability=row['likability'], accuracy=row['accuracy'])\n",
    "\n",
    "        for i in range(len(self.df)):\n",
    "            for j in range(i + 1, len(self.df)):\n",
    "                prob = np.random.random()  \n",
    "                content_similarity = self.similarity_matrix[i, j]\n",
    "                topic_overlap_score = self.topic_overlap(self.topic_matrix[i], self.topic_matrix[j])\n",
    "\n",
    "                combined_weight = (content_similarity + topic_overlap_score) / 2\n",
    "                self.G.add_edge(self.df.loc[i, 'titleSlug'], self.df.loc[j, 'titleSlug'], weight=combined_weight)\n",
    "\n",
    "    def recommend_questions(self, user_id, solved_questions, top_n=3):\n",
    "        # Initialize user skill level if not already set\n",
    "        if user_id not in self.user_skill_levels:\n",
    "            self.user_skill_levels[user_id] = 1  # Starting skill level\n",
    "\n",
    "        recommendations = {}\n",
    "\n",
    "        for solved in solved_questions:\n",
    "            if solved not in self.G:\n",
    "                continue\n",
    "            neighbors = sorted(self.G[solved].items(), key=lambda x: x[1]['weight'], reverse=True)\n",
    "            for neighbor, _ in neighbors:\n",
    "                if neighbor not in solved_questions and neighbor not in self.timeout_problems.get(user_id, []):\n",
    "                    problem_difficulty = self.df[self.df['titleSlug'] == neighbor]['difficulty'].values[0]\n",
    "                    # Map difficulty to skill level (adjust as per requirements)\n",
    "                    mapped_difficulty = self.difficulty_to_skill_level(problem_difficulty)\n",
    "\n",
    "                    # Only recommend problems that match user's current skill level\n",
    "                    if mapped_difficulty <= self.user_skill_levels[user_id]:\n",
    "                        recommendations[neighbor] = self.G[solved][neighbor]['weight']\n",
    "\n",
    "        sorted_recommendations = sorted(recommendations.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Perform belief propagation to adjust the recommendations\n",
    "        self.mrf = self.MarkovRandomField()\n",
    "        self.mrf.add_edge('accuracy', 'difficulty', self.potential_matrix)\n",
    "\n",
    "        # Update belief propagation for each recommendation\n",
    "        cpt = self.belief_propagation(self.mrf)\n",
    "\n",
    "        # Adjust recommendations using belief propagation output\n",
    "        adjusted_recommendations = []\n",
    "        for rec, _ in sorted_recommendations[:top_n]:\n",
    "            # Modify recommendation score using belief propagation (CPT output)\n",
    "            adjustment_factor = cpt.get(('accuracy', 'difficulty'), 1)\n",
    "            adjusted_recommendations.append((rec, adjustment_factor))\n",
    "\n",
    "        return adjusted_recommendations[:top_n]\n",
    "\n",
    "    def difficulty_to_skill_level(self, difficulty):\n",
    "        # Map problem difficulty (1-5) to a skill level (1-100)\n",
    "        skill_mapping = {1: 20, 2: 40, 3: 60, 4: 80, 5: 100}  # Customize as needed\n",
    "        return skill_mapping.get(difficulty, 50)\n",
    "\n",
    "    def update_skill_level(self, user_id, problem, solved):\n",
    "        # Update user skill level after solving or timing out a problem based on difficulty\n",
    "        problem_difficulty = self.df[self.df['titleSlug'] == problem]['difficulty'].values[0]\n",
    "        skill_increment = self.difficulty_to_skill_level(problem_difficulty)\n",
    "\n",
    "        if solved:\n",
    "            self.user_skill_levels[user_id] += skill_increment\n",
    "        else:\n",
    "            # If timed out, decrease skill slightly\n",
    "            self.user_skill_levels[user_id] -= skill_increment / 2\n",
    "\n",
    "        # Make the progression slower after certain levels\n",
    "        self.user_skill_levels[user_id] = np.minimum(self.user_skill_levels[user_id], 100)\n",
    "        self.user_skill_levels[user_id] = np.maximum(self.user_skill_levels[user_id], 1)\n",
    "\n",
    "        # Save updated skill levels to the JSON file\n",
    "        self.save_user_skill_levels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "file_path = \"updated_data.json\"\n",
    "recommender = QuestionRecommender(file_path)\n",
    "\n",
    "user_id = '1'\n",
    "solved_questions = [\"two-sum\", \"add-two-numbers\"]\n",
    "# Recommend questions based on the user's current skill level\n",
    "recommendations = recommender.recommend_questions(user_id, solved_questions, 10)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 1's skill level updated to: 50\n"
     ]
    }
   ],
   "source": [
    "recommender.update_skill_level(user_id, 'add-two-numbers-ii', solved=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# # Usage Example:\n",
    "# recommender = QuestionRecommender()\n",
    "\n",
    "# # Initialize user and solved questions\n",
    "# user_id = '1'\n",
    "solved_questions = [\"two-sum\", \"add-two-numbers\"]\n",
    "# Recommend questions based on the user's current skill level\n",
    "recommendations = recommender.recommend_questions(user_id, solved_questions, 10)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
